{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=['haarcascade_frontalface_default.xml','haarcascade_profileface.xml','haarcascade_frontalface_alt.xml',\n",
    "            'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml']\n",
    "model_list2=['haarcascade_frontalface_default.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not saving bboxes the way I intended. done a bit of messing about with it though. It runs fine, \n",
    "#I'm saving something in there wrong and its returning as if only running default model.\n",
    "\n",
    "\n",
    "def run_opencv_cascade2(file_paths, model, num_threads, scale_factor=1.1, min_neighbors=3, use_grayscale = False, use_gpu = True):\n",
    "    #classifier = cv2.CascadeClassifier(model)\n",
    "    #classifier2 = cv2.CascadeClassifier(model2)\n",
    "    cv2.setNumThreads(num_threads)\n",
    "    #cv2.setScaleFactor(scale_factor)\n",
    "    #cv2.setMinNeighbors(min_neighbors)\n",
    "    counts = []\n",
    "    bboxes = []\n",
    "    #holder={}\n",
    "    #counts2 = []\n",
    "    start_time = timeit.default_timer()\n",
    "    for m in model:\n",
    "        classifier=cv2.CascadeClassifier(m)\n",
    "        start_time1 = timeit.default_timer() \n",
    "        for i in file_paths:\n",
    "            img = cv2.imread(i)\n",
    "            if use_grayscale:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Converting a Mat object to a UMat object enables GPU processing.\n",
    "            if use_gpu:\n",
    "                img = cv2.UMat(img)\n",
    "               \n",
    "            bboxes_found = classifier.detectMultiScale(img, scale_factor, min_neighbors)\n",
    "                        #bboxes2_found = classifier2.detectMultiScale(img, scale_factor, min_neighbors)\n",
    "\n",
    "            bboxes.append(bboxes_found)\n",
    "\n",
    "            counts.append((i, len(bboxes_found)))\n",
    "                    #holder.append((i,len(bboxes_found)))\n",
    "                    #counts2.append((i, len(bboxes2_found)))\n",
    "                    #bboxes.append(bboxes2_found)\n",
    "        end_time1 = timeit.default_timer()\n",
    "        print(end_time1-start_time1)\n",
    "        #holder[m]=counts\n",
    "        \n",
    "    end_time = timeit.default_timer()\n",
    "    test_runtime = end_time - start_time\n",
    "    print(f'Found bounding boxes for {len(counts)} images after {test_runtime} seconds.')\n",
    "    return counts, bboxes #, holder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This passes a single image through all models in list and draws all detected boxes on said image. Then saves it\n",
    "\n",
    "\n",
    "img=cv2.imread('faces/WIDER_train/WIDER_train/images/24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_557.jpg')\n",
    "\n",
    "for m in model_list:\n",
    "    \n",
    "    classifier=cv2.CascadeClassifier(m)\n",
    "    faces=classifier.detectMultiScale(img,scaleFactor=1.1,minNeighbors=3)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w, y+h), (0,255,0),2)\n",
    "    cv2.imwrite('''faces_ex2.jpg''',img)\n",
    "    \n",
    "#img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
