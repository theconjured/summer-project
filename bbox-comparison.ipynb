{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to evaluate the performance of the model, there needs to be a definitive way to measure accuracy.\n",
    "\n",
    "One possible evaluation metric involves using an \"intersection over union\" measurement. It takes the overlapping areas of bounding boxes and divides the total area of both bounding boxes. This produces an accuracy score that can be used to measure how close of a match the bounding boxes area. A score of 1.0 reflects a perfect match, where scores closer to 0 are likely incorrect matches.\n",
    "\n",
    "However, it is also necessary to consider the case that the number of bounding boxes guessed is inaccurate. There are two ways this can happen. In the situation that the number of guessed bounding boxes is lower, the guesses should be matched to the closest real box to determine an error while the missing pairs are automatically considered errors (false negative). Should the number of guesses be higher, each existing box should determine its closest match that is not more proximal to any other box. The left over guesses are considered in the error count as false positives.\n",
    "\n",
    "This is actually not as complex as it sounds. In order to implement this, the the distance is taken from the start of each bounding box in the true set and the test test. The distances are sorted and boxes that have not yet been paired are matched. If there are unmatched true values, the model missed some things that we know are there. If there are unmatched test values, the model found too many faces.\n",
    "\n",
    "For the accurate pairings, the intersection over union calculation is performed to determine an accuracy metric. It's possible to tune the model to increase these ratings and the overall false positive and false negative count.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Consider box1, box2 as [x, y, width, height]\n",
    "def iou(box1, box2):\n",
    "    xa = max(box1[0], box2[0])\n",
    "    ya = max(box1[1], box2[1])\n",
    "    xb = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "    yb = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "    \n",
    "    i_area = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
    "    \n",
    "    a_area = box1[2] * box1[3]\n",
    "    b_area = box2[2] * box2[3]\n",
    "    \n",
    "    return i_area / float(a_area + b_area - i_area)\n",
    "\n",
    "def box_distance(box1, box2):\n",
    "    # sqrt for real cartesian distance but here it doesn't matter, just performance garbler\n",
    "    return (box1[0] - box2[0]) ** 2 + (box1[1] - box2[1]) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ [image_path, image_hash, [bbox1, bbox2, ...]], ... ]\n",
    "def evaluate_performance(ytrue, yhat):\n",
    "    details_structure = {\n",
    "        'image_path': [],\n",
    "        'true_count':[],\n",
    "        'guessed_count':[],\n",
    "        'matches':[],\n",
    "        'false_positives': [],\n",
    "        'false_negatives': [],\n",
    "        'category': [],\n",
    "        'avg_score': [],\n",
    "        \n",
    "    }\n",
    "    results = {\n",
    "        'true_boxes': 0,\n",
    "        'guessed_boxes': 0,\n",
    "        'false_positives': 0,\n",
    "        'false_negatives': 0,\n",
    "        'bad_guesses': 0,        # < .05\n",
    "        'unlikely_guesses': 0,   # < .3\n",
    "        'okay_guesses': 0,       # < .5\n",
    "        'good_guesses': 0,       # < .75\n",
    "        'great_guesses': 0,      # else\n",
    "    }\n",
    "    \n",
    "    for image_path in yhat.keys():\n",
    "        real_boxes = ytrue[image_path][1]\n",
    "        guessed_boxes = yhat[image_path][1]\n",
    "        category = ytrue[image_path][0]\n",
    "        count_real = len(real_boxes)\n",
    "        count_guess = len(guessed_boxes)\n",
    "        distances = []\n",
    "        i = 0\n",
    "        results['true_boxes'] += count_real\n",
    "        results['guessed_boxes'] += count_guess\n",
    "        for b1 in real_boxes:\n",
    "            j = 0\n",
    "            for b2 in guessed_boxes:\n",
    "                distances.append((i, j, box_distance(b1, b2)))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        distances.sort(key = lambda x: x[2])\n",
    "        \n",
    "        assigned_r = [ False for _ in range(count_real)]\n",
    "        assigned_g = [ False for _ in range(count_guess)]\n",
    "        assignments = []\n",
    "        \n",
    "        for d in distances:\n",
    "            if assigned_r[d[0]] or assigned_g[d[1]]:\n",
    "                pass\n",
    "            else:\n",
    "                assigned_r[d[0]] = True\n",
    "                assigned_g[d[1]] = True\n",
    "                assignments.append(d)\n",
    "        \n",
    "        fns = count_real - sum(assigned_r)\n",
    "        fps = count_guess - sum(assigned_g)\n",
    "        scores = [ iou(real_boxes[a[0]], guessed_boxes[a[1]]) for a in assignments ]\n",
    "        score_count = len(scores)\n",
    "        avg_score = score_count > 0 and sum(scores) / score_count or 0\n",
    "        details_structure['image_path'].append(image_path)\n",
    "        details_structure['matches'].append(score_count)\n",
    "        details_structure['true_count'].append(count_real)\n",
    "        details_structure['guessed_count'].append(count_guess)\n",
    "        details_structure['false_positives'].append(fps)\n",
    "        details_structure['false_negatives'].append(fns)\n",
    "        details_structure['category'].append(category)\n",
    "        details_structure['avg_score'].append(avg_score)\n",
    "        results['false_positives'] += fps\n",
    "        results['false_negatives'] += fns\n",
    "        for s in scores:\n",
    "            if s < .05:\n",
    "                results['bad_guesses'] += 1\n",
    "            elif s < .3:\n",
    "                results['unlikely_guesses'] +=1\n",
    "            elif s < .5:\n",
    "                results['okay_guesses'] += 1\n",
    "            elif s < .75:\n",
    "                results['good_guesses'] += 1\n",
    "            else:\n",
    "                results['great_guesses'] += 1\n",
    "    results['details'] = pd.DataFrame(data = details_structure)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some dummy data structures for testing and illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_ytrue = {\n",
    "    'a': [1, [[449, 330, 122, 149]]],\n",
    "    'b': [2, [[361, 98, 263, 339]]],\n",
    "    'c': [3, [[304, 265, 16, 17],[328, 295, 160, 200]]]\n",
    "}\n",
    "\n",
    "fake_yhat = {\n",
    "    'a': [1, [[448, 330, 122, 149],[449, 330, 122, 149]]],\n",
    "    'b': [2, [[361, 98, 263, 339]]],\n",
    "    'c': [3, [[323, 292, 160, 200]]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'true_boxes': 4,\n",
       " 'guessed_boxes': 4,\n",
       " 'false_positives': 1,\n",
       " 'false_negatives': 1,\n",
       " 'bad_guesses': 0,\n",
       " 'unlikely_guesses': 0,\n",
       " 'okay_guesses': 0,\n",
       " 'good_guesses': 0,\n",
       " 'great_guesses': 3,\n",
       " 'details':   image_path  true_count  guessed_count  matches  false_positives  \\\n",
       " 0          a           1              2        1                1   \n",
       " 1          b           1              1        1                0   \n",
       " 2          c           2              1        1                0   \n",
       " \n",
       "    false_negatives  category  avg_score  \n",
       " 0                0         1   1.030381  \n",
       " 1                0         2   1.013619  \n",
       " 2                1         3   0.932834  }"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_performance(fake_ytrue, fake_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_results(info, boxes):\n",
    "    results = {}\n",
    "    for f in info.keys():\n",
    "        results[f] = [ int(f.split('--')[0]), [ [r.x, r.y, r.width, r.height] for r in \n",
    "            boxes[boxes['image_path'] == f].itertuples() ] ]\n",
    "    return results\n",
    "\n",
    "def get_trial_notes(trial):\n",
    "    con = sqlite3.connect('results.db')\n",
    "    res = pd.read_sql_query('select notes, model_name from trials where id = ?', con, params = (trial,))\n",
    "    con.close()\n",
    "    return (res.iloc[0].model_name, res.iloc[0].notes)\n",
    "\n",
    "def fetch_results(trial):\n",
    "    con = sqlite3.connect('results.db')\n",
    "    bbox = pd.read_sql_query('select * from trials_bbx where trial_id = ?', con, params = (trial,))\n",
    "    counts = pd.read_sql_query('select * from trials_counts where trial_id = ?', con, params = (trial,))\n",
    "    counts_dict = pd.Series(counts.box_count.values, index = counts.image_path).to_dict()\n",
    "    con.close()\n",
    "    return transform_results(counts_dict, bbox)\n",
    "    \n",
    "def fetch_true(use_val = False, sample_pct = 1, sample_seed = 1):\n",
    "    con = sqlite3.connect('widerface.db')\n",
    "    db_str = ['val','train']\n",
    "    bbox = pd.read_sql_query(f'select * from bbx_{use_val and db_str[0] or db_str[1]}  where invalid = 0 and width * height > 25', con)\n",
    "    counts = bbox.image_path.value_counts()\n",
    "    con.close()\n",
    "    return transform_results(counts, bbox)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draws bounding boxes for a specific image given a path, true boxes, and guessed boxes. True boxes are green while guessed boxes are red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_path, true_boxes, guessed_boxes, path_prefix, out_dir):\n",
    "    i = cv2.imread(f'{path_prefix}/{image_path}', cv2.IMREAD_COLOR)\n",
    "    for b in true_boxes:\n",
    "        x1 = b[0]\n",
    "        y1 = b[1]\n",
    "        x2 = b[0] + b[2]\n",
    "        y2 = b[1] + b[3]\n",
    "        cv2.rectangle(i, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    for b in guessed_boxes:\n",
    "        x1 = b[0]\n",
    "        y1 = b[1]\n",
    "        x2 = b[0] + b[2]\n",
    "        y2 = b[1] + b[3]\n",
    "        cv2.rectangle(i, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    i2 = i[:,:,::-1]\n",
    "    img_name = image_path.split('/')[1]\n",
    "    save_path = f'{out_dir}/{img_name}'\n",
    "    cv2.imwrite(save_path, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get real bounding box data in the correct format. This may take a bit. It is necessary to run this before doing any comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = fetch_true() # Training boxes\n",
    "# ytrue = fetch_true(True) # Validation boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data for a given trial. Again, this may take a bit. You can get information about a trial number with get_trial_notes(#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('haar', 'scale: 1.1, neighbors: 3, 5% sample')\n"
     ]
    }
   ],
   "source": [
    "print(get_trial_notes(11))\n",
    "yhat = fetch_results(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the difference in guessed boxes and false positives should equal the sum of every guess rating. The sum of this and false negatives (missed boxes) should match the true total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_results_analysis(res):\n",
    "    predicted = res['guessed_boxes'] - res['false_positives']\n",
    "    guess_sum = res['bad_guesses'] + res['unlikely_guesses'] + res['okay_guesses'] + res['good_guesses'] + res['great_guesses']\n",
    "    good_guesses = res['okay_guesses'] + res['good_guesses'] + res['great_guesses']\n",
    "    assert(predicted == guess_sum)\n",
    "    assert(predicted + res['false_negatives'] == res['true_boxes'])\n",
    "    print(f'This model idenitified {res[\"guessed_boxes\"]} total bounding boxes, though {res[\"false_positives\"]} of them did not correspond to a real bounding box.\\n'\n",
    "    + f'{res[\"false_negatives\"]} known boxes failed to be identified ({round(res[\"false_negatives\"] / res[\"true_boxes\"] * 100, 2)}%).\\n'\n",
    "    + f'Of the guessed boxes, {res[\"bad_guesses\"]} were very unlikely to be a match and {res[\"unlikely_guesses\"]} are probably not accurate.\\n'\n",
    "    + f'{good_guesses} ({round(good_guesses / res[\"true_boxes\"] * 100, 2)}% of total) were identified with reasonably high confidence.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will draw all bounding boxes for a test set. If the limit is set, it will stop after that many images. The *out_dir* must exist on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_test_true_comparison(yhat, limit = -1, path_prefix = './data/train/images/', out_dir = './data/results'):\n",
    "    count = 0\n",
    "    for i in test.items():\n",
    "        image_path = i[0]\n",
    "        guessed_boxes = i[1][1]\n",
    "        true_boxes = ytrue[image_path][1]\n",
    "        draw_boxes(image_path, true_boxes, guessed_boxes, path_prefix, out_dir)\n",
    "        count += 1\n",
    "        if limit > 0 and count >= limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic performance analysis method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model idenitified 2678 total bounding boxes, though 772 of them did not correspond to a real bounding box.\n",
      "4914 known boxes failed to be identified (72.05%).\n",
      "Of the guessed boxes, 750 were very unlikely to be a match and 85 are probably not accurate.\n",
      "1071 (15.7% of total) were identified with reasonably high confidence.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>true_count</th>\n",
       "      <th>guessed_count</th>\n",
       "      <th>matches</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>category</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>35--Basketball/35_Basketball_basketballgame_ba...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3--Riot/3_Riot_Riot_3_634.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43--Row_Boat/43_Row_Boat_Canoe_43_400.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.734443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40--Gymnastics/40_Gymnastics_Gymnastics_40_439...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.732838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16--Award_Ceremony/16_Award_Ceremony_Awards_Ce...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.742258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>639</td>\n",
       "      <td>35--Basketball/35_Basketball_basketballgame_ba...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>39--Ice_Skating/39_Ice_Skating_Ice_Skating_39_...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.420409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>5--Car_Accident/5_Car_Accident_Accident_5_332.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>5--Car_Accident/5_Car_Accident_Accident_5_810.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>10--People_Marching/10_People_Marching_People_...</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>0.678103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  true_count  \\\n",
       "0    35--Basketball/35_Basketball_basketballgame_ba...           3   \n",
       "1                        3--Riot/3_Riot_Riot_3_634.jpg           4   \n",
       "2            43--Row_Boat/43_Row_Boat_Canoe_43_400.jpg           2   \n",
       "3    40--Gymnastics/40_Gymnastics_Gymnastics_40_439...           1   \n",
       "4    16--Award_Ceremony/16_Award_Ceremony_Awards_Ce...           1   \n",
       "..                                                 ...         ...   \n",
       "639  35--Basketball/35_Basketball_basketballgame_ba...           8   \n",
       "640  39--Ice_Skating/39_Ice_Skating_Ice_Skating_39_...           1   \n",
       "641  5--Car_Accident/5_Car_Accident_Accident_5_332.jpg           1   \n",
       "642  5--Car_Accident/5_Car_Accident_Accident_5_810.jpg           1   \n",
       "643  10--People_Marching/10_People_Marching_People_...          47   \n",
       "\n",
       "     guessed_count  matches  false_positives  false_negatives  category  \\\n",
       "0                4        3                1                0        35   \n",
       "1                8        4                4                0         3   \n",
       "2                3        2                1                0        43   \n",
       "3                7        1                6                0        40   \n",
       "4                5        1                4                0        16   \n",
       "..             ...      ...              ...              ...       ...   \n",
       "639              2        2                0                6        35   \n",
       "640              4        1                3                0        39   \n",
       "641              0        0                0                1         5   \n",
       "642              5        1                4                0         5   \n",
       "643             10       10                0               37        10   \n",
       "\n",
       "     avg_score  \n",
       "0     0.000000  \n",
       "1     0.708929  \n",
       "2     0.734443  \n",
       "3     0.732838  \n",
       "4     0.742258  \n",
       "..         ...  \n",
       "639   0.000000  \n",
       "640   0.420409  \n",
       "641   0.000000  \n",
       "642   0.000000  \n",
       "643   0.678103  \n",
       "\n",
       "[644 rows x 8 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evaluate_performance(ytrue, yhat)\n",
    "basic_results_analysis(res)\n",
    "res['details']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing boxes example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_test_true_comparison(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
